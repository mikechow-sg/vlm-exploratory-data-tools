{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 4: Test Exploratory Coding (First Iteration)\n",
    "This notebook documents the first batch of integrated coding with the VLM. This was applied to a random 5 videos constituted of 95 frames from outside the date range of the main dataset.\n",
    "\n",
    "**Prompt List:**\n",
    "1. Prompt 3a\n",
    "\n",
    "> You are an expert annotator of social media videos. You are provided a still image from a video. Your job is to analyze the backdrop of the image and classify it into the following five mutually exclusive setting categories. Ignore any text overlay or captions. For the provided image, select the one category that best describes its background or setting based on its definition: Graphics: Image does not contain live-action imagery (e.g., animations, CGI, black screens); Outdoor combat: Image set outdoors containing explicit signs of warfare such as visible destruction, military hardware or active combat; Outdoor non-combat: Image set outdoors WITHOUT explicit signs of warfare. This includes urban or natural landscapes without weapons or destruction; Indoor combat: Image set indoors containing explicit signs of warfare such as visible destruction, rubble, military hardware or active combat. This includes damaged interiors and confined combat settings (such as tunnels); Indoor non-combat: Image set indoors WITHOUT explicit signs of warfare. This includes studio environments and homes without weapons or destruction. Analyze the provided still and reply with one of these exact labels: “Graphics”, “Outdoor combat”, “Outdoor non‑combat”, “Indoor combat”, or “Indoor non‑combat”.\n",
    "\n",
    "---\n",
    "\n",
    "2. Prompt 3b (Includes motivation)\n",
    "\n",
    "> You are an expert annotator of social media videos. You are provided a still image from a video. Your job is to analyze the backdrop of the image and classify it into the following six mutually exclusive setting categories. Ignore any text overlay or captions. For the provided image, select the one category that best describes its background or setting based on its definition: Graphics: Image is artificial or non–live‑action imagery (e.g., animations, CGI, black screens); Outdoor combat: Image set outdoors containing explicit signs of warfare such as visible destruction, military hardware or active combat; Outdoor non-combat: Image set outdoors WITHOUT explicit signs of warfare. This includes urban or natural landscapes without weapons or destruction; Indoor combat: Image set indoors containing explicit signs of warfare such as visible destruction, rubble, military hardware or active combat. This includes damaged interiors and confined combat settings (such as tunnels); Indoor non-combat: Image set indoors WITHOUT explicit signs of warfare. This includes studio environments and homes without weapons or destruction. Respond with a Python-style tuple in the format: (\"classification\", \"motivation\") - \"classification\" must be one of: \"Graphics\", \"Outdoor combat\", \"Outdoor non-combat\", \"Indoor combat\", or \"Indoor non-combat\"; \"motivation\" is a justification of your classification in 50 words or fewer, explaining what visual elements in the image led to your choice.\n",
    "\n",
    "---\n",
    "\n",
    "3. Prompt 3c (Motivation and option for \"Uncertain\")\n",
    "\n",
    "> You are an expert annotator of social media videos. You are provided a still image from a video. Your job is to analyze the backdrop of the image and classify it into the following six mutually exclusive setting categories. Ignore any text overlay or captions. For the provided image, select the one category that best describes its background or setting based on its definition: Graphics: Image is artificial or non–live‑action imagery (e.g., animations, CGI, black screens); Outdoor combat: Image set outdoors containing explicit signs of warfare such as visible destruction, military hardware or active combat; Outdoor non-combat: Image set outdoors WITHOUT explicit signs of warfare. This includes urban or natural landscapes without weapons or destruction; Indoor combat: Image set indoors containing explicit signs of warfare such as visible destruction, rubble, military hardware or active combat. This includes damaged interiors and confined combat settings (such as tunnels); Indoor non-combat: Image set indoors WITHOUT explicit signs of warfare. This includes studio environments and homes without weapons or destruction. However, if you are uncertain, return 'Uncertain'.  Respond with a Python-style tuple in the format: (\"classification\", \"motivation\") - \"classification\" must be one of: \"Graphics\", \"Outdoor combat\", \"Outdoor non-combat\", \"Indoor combat\", \"Indoor non-combat\", or “Uncertain; \"motivation\" is a justification of your classification in 50 words or fewer, explaining what visual elements in the image led to your choice or uncertainty.\n"
   ],
   "id": "819ebb41c3876338"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import face_recognition\n",
    "import re\n",
    "import ast\n",
    "import krippendorff\n",
    "import networkx as nx"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Establish directory\n",
    "frames_folder = ''\n",
    "coding_main_vlm_path = ''\n",
    "coding_m_path = ''\n",
    "coding_c_path = ''"
   ],
   "id": "e6867fb18cde3880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Clean up original VLM Data\n",
    "This section takes the original VLM data and parses it"
   ],
   "id": "528c1d203e7a5aeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding_main = pd.read_csv(coding_main_vlm_path)\n",
    "df_coding_main"
   ],
   "id": "44edfda826a5f555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function for safe eval of tuples\n",
    "def safe_eval(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Error parsing '{value}'\")\n",
    "        return None  # Return None or any fallback value for invalid strings\n"
   ],
   "id": "35b696c7a57e7e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert column into tuple\n",
    "df_coding_main['setting_vlm_3b_tuple'] = df_coding_main['setting_vlm_3b_tuple'].apply(safe_eval)"
   ],
   "id": "15c327ce0af80e44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split tuples into results and motivation\n",
    "for i, scene in df_coding_main.iterrows():\n",
    "    tuple_value = scene['setting_vlm_3b_tuple']\n",
    "    if tuple_value is not None:\n",
    "        result = tuple_value[0]\n",
    "        motivation = tuple_value[1]\n",
    "        df_coding_main.loc[i, 'setting_vlm_3b'] = result\n",
    "        df_coding_main.loc[i, 'setting_vlm_3b_motivation'] = motivation\n",
    "        print(f\"Classification result: {result} Motivation: {motivation}\")\n",
    "        print()\n"
   ],
   "id": "241e2a5a4a79786a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Repeat for 03\n",
    "df_coding_main['setting_vlm_3c_tuple'] = df_coding_main['setting_vlm_3c_tuple'].apply(safe_eval)\n",
    "\n",
    "# Split tuples into results and motivation\n",
    "for i, scene in df_coding_main.iterrows():\n",
    "    tuple_value = scene['setting_vlm_3c_tuple']\n",
    "    if tuple_value is not None:\n",
    "        result = tuple_value[0]\n",
    "        motivation = tuple_value[1]\n",
    "        df_coding_main.loc[i, 'setting_vlm_3c'] = result\n",
    "        df_coding_main.loc[i, 'setting_vlm_3c_motivation'] = motivation\n",
    "        print(f\"Classification result: {result} Motivation: {motivation}\")\n",
    "        print()"
   ],
   "id": "6554201e93e66e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_coding_main",
   "id": "6fa8b33e3445f62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Coerce columns formatting\n",
    "df_coding_main['setting_vlm_3a'] = df_coding_main['setting_vlm_3a'].str.lower().str.capitalize()\n",
    "df_coding_main['setting_vlm_3b'] = df_coding_main['setting_vlm_3b'].str.lower().str.capitalize()\n",
    "df_coding_main['setting_vlm_3c'] = df_coding_main['setting_vlm_3c'].str.lower().str.capitalize()\n",
    "\n",
    "df_coding_main"
   ],
   "id": "d705233cbe8c3ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Bring in manually coded sheets\n",
    "`df_coding_m` is the primary coder whereas `df_coding_c` is the secondary coder."
   ],
   "id": "8c34de0b05d802b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding_m = pd.read_csv(coding_m_path)\n",
    "df_coding_c = pd.read_csv(coding_c_path)"
   ],
   "id": "a649225902bd5c20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding = pd.merge(df_coding_main, df_coding_m, how='left')\n",
    "df_coding"
   ],
   "id": "767a3c366a0b7403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding = pd.merge(df_coding, df_coding_c, how='left')\n",
    "df_coding"
   ],
   "id": "357f4b5cf14b5e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare distributions quickly\n",
    "print(df_coding['setting_m'].value_counts())\n",
    "print(df_coding['setting_c'].value_counts())\n",
    "print(df_coding['setting_vlm_3a'].value_counts())\n",
    "print(df_coding['setting_vlm_3b'].value_counts())\n",
    "print(df_coding['setting_vlm_3c'].value_counts())\n"
   ],
   "id": "e8c65e99d6c10841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_coding.to_csv('', index=False)",
   "id": "6f1383972d4539f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_coding = pd.read_csv('')",
   "id": "6d2a28502decca12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of results\n",
    "Here we will review the results of the coding, by calculating the intercoder reliability as well as manually reviewing the motivations provided by the VLM."
   ],
   "id": "80d79c36b1364959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_for_alpha(df):\n",
    "    \"\"\"\n",
    "    Preprocess DataFrame columns to encode categorical values as numeric.\n",
    "    This dynamically handles categorical data and missing values (NaN).\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Use pandas' factorization to encode categories into integer values\n",
    "    for column in df_processed.columns:\n",
    "        df_processed[column], _ = pd.factorize(df_processed[column], use_na_sentinel=True)\n",
    "        # Replace factorized -1 (used for NaN) with np.nan for proper handling\n",
    "        # df_processed[column] = df_processed[column].replace(-1, np.nan)\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "\n",
    "def calc_alpha(df, level_of_measurement='nominal'):\n",
    "\n",
    "    # Preprocess the data\n",
    "    # df_numeric = preprocess_for_alpha(df)\n",
    "\n",
    "    ratings = df.to_numpy().T\n",
    "\n",
    "    alpha = krippendorff.alpha(ratings, level_of_measurement=level_of_measurement)\n",
    "    # print(f\"Krippendorff's Alpha: {alpha}\")\n",
    "    return alpha\n"
   ],
   "id": "209a2c9a3517ab94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Manually refactor code categories\n",
    "setting_refactor = {'Graphics' : 1,\n",
    "                    'Indoor combat': 2,\n",
    "                    'Indoor non-combat': 3,\n",
    "                    'Outdoor combat': 4,\n",
    "                    'Outdoor non-combat': 5,\n",
    "                    'Uncertain': np.nan}"
   ],
   "id": "392d54575c526e91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check Intercoder reliability\n",
    "# Define the combinations of columns to be compared\n",
    "df_intercoder_alpha = pd.DataFrame([\n",
    "    {'column_1':'setting_m','column_2':'setting_c','type':'setting'},\n",
    "\n",
    "    {'column_1':'setting_m','column_2':'setting_vlm_3a','type':'setting'},\n",
    "    {'column_1':'setting_c','column_2':'setting_vlm_3a','type':'setting'},\n",
    "\n",
    "    {'column_1':'setting_m','column_2':'setting_vlm_3b','type':'setting'},\n",
    "    {'column_1':'setting_c','column_2':'setting_vlm_3b','type':'setting'},\n",
    "\n",
    "    {'column_1':'setting_m','column_2':'setting_vlm_3c','type':'setting'},\n",
    "    {'column_1':'setting_c','column_2':'setting_vlm_3c','type':'setting'},\n",
    "\n",
    "    {'column_1':'setting_vlm_3a','column_2':'setting_vlm_3b','type':'setting'},\n",
    "    {'column_1':'setting_vlm_3a','column_2':'setting_vlm_3c','type':'setting'},\n",
    "    {'column_1':'setting_vlm_3b','column_2':'setting_vlm_3c','type':'setting'},\n",
    "\n",
    "])\n"
   ],
   "id": "44eb01bee22f9682",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, row in df_intercoder_alpha.iterrows():\n",
    "    column_1 = row['column_1']\n",
    "    column_2 = row['column_2']\n",
    "    coding_type = row['type']\n",
    "    if coding_type == 'setting':\n",
    "        refactor_dict = setting_refactor\n",
    "\n",
    "    df_intercoder = df_coding[[column_1, column_2]].copy()\n",
    "    df_intercoder[column_1] =  df_intercoder[column_1].map(refactor_dict)\n",
    "    df_intercoder[column_2] =  df_intercoder[column_2].map(refactor_dict)\n",
    "\n",
    "\n",
    "    df_intercoder = df_intercoder.replace(-1, np.nan)\n",
    "\n",
    "    # print(df_intercoder)\n",
    "\n",
    "    df_intercoder_alpha.loc[i, 'intercoder_alpha'] = calc_alpha(df_intercoder[[column_1, column_2]])\n",
    "\n"
   ],
   "id": "ee4e541f90fce16b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_intercoder_alpha",
   "id": "d37089f2a550ed85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Reviewing this, we can see that the VLM is generally stable within their annotations. It is particularly strong with and without the \"Uncertain\" option. This is a good sign.\n",
    "\n",
    "Between the human coders, the agreement is acceptable but could be better. The agreements with the VLM were less than the minimum acceptable threshold of 0.667. Interestingly, the VLM agreed with the secondary coder moreso than myself."
   ],
   "id": "57018050a5a9258c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter for visualization to avoid clutter\n",
    "df_intercoder_alpha_select = df_intercoder_alpha.loc[[0,3,4]]\n",
    "df_intercoder_alpha_select"
   ],
   "id": "8d5738316ba830c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df_intercoder_alpha_select)",
   "id": "4bf09fe4bb8a10e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize as network diagram\n",
    "def viz_agreement_network(df, output_path=None):\n",
    "\n",
    "    # Initialize the graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # List of nodes\n",
    "    nodes = list(set(df['column_1'].tolist() + df['column_2'].tolist()))\n",
    "    G.add_nodes_from(nodes)\n",
    "\n",
    "    # Add edges with weights\n",
    "    for i, row in df.iterrows():\n",
    "        G.add_edge(row['column_1'], row['column_2'], weight=row['intercoder_alpha'])\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(10,10))\n",
    "    pos = nx.spring_layout(G)  # Layout algorithm for positions\n",
    "    edges = G.edges(data=True)\n",
    "\n",
    "    # Prepare edge widths based on intercoder_alpha\n",
    "    widths = [d['weight'] * 30 for (u, v, d) in edges]  # multiplied for visibility\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color='skyblue',\n",
    "            width=widths, edge_color='blue', alpha=0.6,\n",
    "            font_size=10, font_weight='bold')\n",
    "\n",
    "    # # Add edge labels to show scores\n",
    "    # edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in edges}\n",
    "    # nx.draw_network_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "\n",
    "    plt.title(\"Intercoder Agreement Network\")\n",
    "    plt.axis('off')\n",
    "    if output_path is not None:\n",
    "        plt.savefig(output_path)\n",
    "    plt.show()"
   ],
   "id": "6835b343ae1fa78a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viz_agreement_network(df_intercoder_alpha_select, '')",
   "id": "a13ac4386f22a080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Because they are so near each other, they look visually identical with one another unfortunately.",
   "id": "bad3b4ddfcf3d982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualizing results for review\n",
    "We can now visualize the results and motivations to review.\n",
    "In the interest of reducing clutter, only prompt 3b and 3c were reviewed."
   ],
   "id": "d1eca514a3abb482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import textwrap\n",
    "# Visualize each prediction (setting)\n",
    "for index, scene in df_coding.iterrows():\n",
    "    video_id = scene['url']\n",
    "    scene_id = scene['id']\n",
    "\n",
    "    cleaned_id = re.sub(r'\\.mp4', '', scene_id)\n",
    "    image_path = os.path.join(frames_folder, str(video_id), f'{cleaned_id}.jpeg')\n",
    "    image = face_recognition.load_image_file(image_path) # load image\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(f\"Coding result for {scene_id}\", fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Set up textwrap\n",
    "    max_width = 30\n",
    "\n",
    "    setting_m = scene['setting_m']\n",
    "    setting_c = scene['setting_c']\n",
    "    setting_vlm_3b = scene['setting_vlm_3b']\n",
    "    setting_vlm_3b_motivate = scene['setting_vlm_3b_motivation']\n",
    "    wrapped_motivation_3b = textwrap.fill(setting_vlm_3b_motivate, width=max_width)\n",
    "\n",
    "    setting_vlm_3c = scene['setting_vlm_3c']\n",
    "    setting_vlm_3c_motivate = scene['setting_vlm_3c_motivation']\n",
    "    wrapped_motivation_3c = textwrap.fill(setting_vlm_3c_motivate, width=max_width)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if setting_m == setting_c:\n",
    "        human_match = 'Match'\n",
    "    else:\n",
    "        human_match = 'No match'\n",
    "\n",
    "    if setting_c == setting_vlm_3b and setting_m == setting_vlm_3b:\n",
    "        vlm_match_3b = 'Match'\n",
    "    else:\n",
    "        vlm_match_3b = 'No match'\n",
    "\n",
    "    if setting_c == setting_vlm_3c and setting_m == setting_vlm_3c:\n",
    "        vlm_match_3c = 'Match'\n",
    "    else:\n",
    "        vlm_match_3c = 'No match'\n",
    "\n",
    "\n",
    "    annotation = f'Pri Coder: {setting_m} \\nSec Coder: {setting_c}\\n' \\\n",
    "    f'Human coder match: {human_match}\\n\\n' \\\n",
    "    f'VLM (3B): {setting_vlm_3b}\\nMotivation: {wrapped_motivation_3b}\\n' \\\n",
    "    f'VLM match: {vlm_match_3b}\\n\\n' \\\n",
    "    f'VLM (3C): {setting_vlm_3c}\\nMotivation: {wrapped_motivation_3c}\\n' \\\n",
    "    f'VLM match: {vlm_match_3c}' \\\n",
    "    # Annotate on the middle-right side of the image\n",
    "    plt.annotate(\n",
    "        annotation,\n",
    "        xy=(1.05, 0.5),  # Position: 1.05 means slightly to the right of the axes\n",
    "        xycoords='axes fraction',  # Position relative to axes (not data coordinates)\n",
    "        fontsize=10,\n",
    "        ha='left',  # Align text to the left\n",
    "        va='center',  # Vertically centered\n",
    "        bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white')  # Add highlight box\n",
    "    )\n",
    "    # Adjust spacing\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "4b3c82ea26161d97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reprocessing and splitting setting\n",
    "We realized that the combined dimensions were likely depressing the agreement results. Thus, we decided to split them."
   ],
   "id": "7f4ae2b42b11dcd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_coding = pd.read_csv('')",
   "id": "759945f762f91a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_setting(setting_str):\n",
    "\n",
    "    combat_presence = ''\n",
    "    location = ''\n",
    "    if setting_str == 'Graphics':\n",
    "        location = 'Graphics'\n",
    "        combat_presence = 'Graphics'\n",
    "    elif setting_str == 'Uncertain':\n",
    "        location = 'Uncertain'\n",
    "        combat_presence = 'Uncertain'\n",
    "    else:\n",
    "        if 'Outdoor' in setting_str:\n",
    "            location = 'Outdoor'\n",
    "        elif 'Indoor' in setting_str:\n",
    "            location = 'Indoor'\n",
    "        if 'non-combat' in setting_str:\n",
    "            combat_presence = 'Non-combat'\n",
    "        elif 'combat' in setting_str and 'non-combat' not in setting_str:\n",
    "            combat_presence = 'Combat'\n",
    "\n",
    "    # Error checking\n",
    "    if combat_presence == '' or location == '':\n",
    "        print(f\"Error: Setting {setting_str} is not recognized.\")\n",
    "\n",
    "    return location, combat_presence\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7d413e5bce12989c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding['location_vlm_3c'], df_coding['combat_presence_vlm_3c'] = zip(*df_coding['setting_vlm_3c'].apply(split_setting))\n",
    "\n",
    "df_coding['location_vlm_3b'], df_coding['combat_presence_vlm_3b'] = zip(*df_coding['setting_vlm_3b'].apply(split_setting))\n",
    "df_coding['location_vlm_3a'], df_coding['combat_presence_vlm_3a'] = zip(*df_coding['setting_vlm_3a'].apply(split_setting))\n",
    "df_coding['location_m'], df_coding['combat_presence_m'] = zip(*df_coding['setting_m'].apply(split_setting))\n",
    "df_coding['location_c'], df_coding['combat_presence_c'] = zip(*df_coding['setting_c'].apply(split_setting))\n"
   ],
   "id": "4b291d0f6691f37a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_coding\n",
    "\n"
   ],
   "id": "f0896c2252174fbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# update\n",
    "df_coding.to_csv('')"
   ],
   "id": "e8173acb4355fa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Establish new refactor\n",
    "\n",
    "location_refactor = {'Graphics' : 1,\n",
    "                    'Indoor': 2,\n",
    "                    'Outdoor': 3,\n",
    "                    'Uncertain': np.nan}\n",
    "\n",
    "combat_presence_refactor = {'Graphics' : 1,\n",
    "                    'Combat': 2,\n",
    "                    'Non-combat': 3,\n",
    "                    'Uncertain': np.nan}"
   ],
   "id": "f8f2fcad8e780835",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check Calculate new intercoder agreement\n",
    "\n",
    "# Define the columns to be compared\n",
    "df_intercoder_location_combat_presence = pd.DataFrame([\n",
    "\n",
    "    {'column_1':'location_m','column_2':'location_c','type':'location'},\n",
    "    {'column_1':'location_m','column_2':'location_vlm_3a','type':'location'},\n",
    "    {'column_1':'location_c','column_2':'location_vlm_3a','type':'location'},\n",
    "    {'column_1':'location_m','column_2':'location_vlm_3b','type':'location'},\n",
    "    {'column_1':'location_c','column_2':'location_vlm_3b','type':'location'},\n",
    "    {'column_1':'location_m','column_2':'location_vlm_3c','type':'location'},\n",
    "    {'column_1':'location_c','column_2':'location_vlm_3c','type':'location'},\n",
    "    {'column_1':'location_vlm_3a','column_2':'location_vlm_3b','type':'location'},\n",
    "    {'column_1':'location_vlm_3a','column_2':'location_vlm_3c','type':'location'},\n",
    "    {'column_1':'location_vlm_3b','column_2':'location_vlm_3c','type':'location'},\n",
    "\n",
    "    {'column_1':'combat_presence_m','column_2':'combat_presence_c','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_m','column_2':'combat_presence_vlm_3a','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_c','column_2':'combat_presence_vlm_3a','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_m','column_2':'combat_presence_vlm_3b','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_c','column_2':'combat_presence_vlm_3b','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_m','column_2':'combat_presence_vlm_3c','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_c','column_2':'combat_presence_vlm_3c','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_vlm_3a','column_2':'combat_presence_vlm_3b','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_vlm_3a','column_2':'combat_presence_vlm_3c','type':'combat_presence'},\n",
    "    {'column_1':'combat_presence_vlm_3b','column_2':'combat_presence_vlm_3c','type':'combat_presence'},\n",
    "\n",
    "\n",
    "])\n"
   ],
   "id": "38cb63724239a7d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate reliability\n",
    "for i, row in df_intercoder_location_combat_presence.iterrows():\n",
    "    column_1 = row['column_1']\n",
    "    column_2 = row['column_2']\n",
    "    coding_type = row['type']\n",
    "    # if coding_type == 'setting':\n",
    "    #     refactor_dict = setting_refactor\n",
    "    #\n",
    "    if coding_type == 'location':\n",
    "        refactor_dict = location_refactor\n",
    "    elif coding_type == 'combat_presence':\n",
    "        refactor_dict = combat_presence_refactor\n",
    "\n",
    "    df_intercoder = df_coding[[column_1, column_2]].copy()\n",
    "    df_intercoder[column_1] =  df_intercoder[column_1].map(refactor_dict)\n",
    "    df_intercoder[column_2] =  df_intercoder[column_2].map(refactor_dict)\n",
    "\n",
    "\n",
    "    df_intercoder = df_intercoder.replace(-1, np.nan)\n",
    "\n",
    "    # print(df_intercoder)\n",
    "\n",
    "    df_intercoder_location_combat_presence.loc[i, 'intercoder_alpha'] = calc_alpha(df_intercoder[[column_1, column_2]])"
   ],
   "id": "39564d107d40d820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_intercoder_location_combat_presence",
   "id": "2ac885656f5bec4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As suspected, combat presence was specifically the culprit of deflating the agreement scores. In fact, the VLM's agreement with myself and the secondary coder separately was higher than myself with the secondary coder! This thus allows us to focus on combat presence as a problem point.",
   "id": "28ffbaa723ba9aa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter and visualize as networks again\n",
    "df_intercoder_location = df_intercoder_location_combat_presence.loc[[0,3,4]]\n",
    "df_intercoder_location"
   ],
   "id": "96d7c56a935beabf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viz_agreement_network(df_intercoder_location, '')",
   "id": "48b891fa5cffa34c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_intercoder_combat_presence = df_intercoder_location_combat_presence.loc[[10,13,14]]\n",
    "df_intercoder_combat_presence"
   ],
   "id": "cb5c898b4681509e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "viz_agreement_network(df_intercoder_combat_presence, '')",
   "id": "f3ca24656c7a1264",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
